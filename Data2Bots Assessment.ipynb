{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46cc1972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Successfully Initialised\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author : Oluwaloseyi Sufianu Sekoni\n",
    "Role: Data Engineer @ Data2Bots\n",
    "Date of Creation: 22nd May, 2023\n",
    "'''\n",
    "\n",
    "#Initialise Local Spark Instance\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "#Import Supporting ETL libraries\n",
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row\n",
    "import botocore\n",
    "import boto3\n",
    "\n",
    "# Define path to JDBC driver for Postgres Connections \n",
    "PATH_TO_JAR_FILE = r\"C:\\SparkApp\\spark-3.4.0-bin-hadoop3\\jars\\postgresql-42.6.0.jar\"\n",
    "\n",
    "# create spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[1]')\\\n",
    "    .appName(\"Data2Bots_ETL\")\\\n",
    "    .config(\"spark.jars\", PATH_TO_JAR_FILE)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "spark\n",
    "\n",
    "print('Spark Successfully Initialised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f8ca439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://THANOS:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Data2Bots_ETL</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2df32cae880>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0bfc826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Sucessfully\n"
     ]
    }
   ],
   "source": [
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "\n",
    "# Use the client\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED), region_name = 'eu-central-1')\n",
    "\n",
    "print('Completed Sucessfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f454389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bucket exists\n",
      "Connection to AWS S3 is successful\n"
     ]
    }
   ],
   "source": [
    "bucket =s3.list_objects_v2(Bucket='d2b-internal-assessment-bucket')\n",
    "\n",
    "if bucket['Name'] == 'd2b-internal-assessment-bucket':\n",
    "    print(\"The bucket exists\")\n",
    "else:\n",
    "    print(\"The bucket does not exist\")\n",
    "\n",
    "print('Connection to AWS S3 is successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7214a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to Bucket containing json files\n",
    "response = s3.list_objects_v2(Bucket='d2b-internal-assessment-bucket')\n",
    "\n",
    "# Get Bucket Contents\n",
    "files = response.get(\"Contents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "487c1847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Function Created Successfully\n"
     ]
    }
   ],
   "source": [
    "#Define Destination Connection to AWS PostgresDB amd Load Operation as a Function\n",
    "def jdbc_load_function(to_load, write_mode, tab_name):\n",
    "    servername = \"d2b-internal-assessment-dwh.cxeuj0ektqdz.eu-central-1.rds.amazonaws.com\"\n",
    "    portnumber = 5432\n",
    "    dbname = \"d2b_assessment\"\n",
    "    username = \"oluwseko3351\"\n",
    "    password = \"QWjmGssQaY\"\n",
    "\n",
    "    URL = f\"jdbc:postgresql://{servername}:{portnumber}/{dbname}\"\n",
    "    print('JDBC URL Created')\n",
    "\n",
    "    load_query = '''{to_load}.write.mode(\"{write_mode}\")\\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\",URL)\\\n",
    "    .option(\"dbtable\", \"oluwseko3351_staging.{tab_name}\")\\\n",
    "    .option(\"user\", username)\\\n",
    "    .option(\"password\", \"QWjmGssQaY\")\\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\\\n",
    "    .save()'''.format(to_load = \"dataset\",write_mode=write_mode, tab_name = tab_name)\n",
    "\n",
    "    exec(load_query)\n",
    "    \n",
    "    final_message = '''Table Loading is Complete.\\n\\nPlease check PostgresDB for table:{tab_name}\\n\\nTables was generated from:{tab_name}.csv\n",
    "    '''.format(tab_name=tab_name)\n",
    "    \n",
    "    print(final_message)\n",
    "    \n",
    "print('Load Function Created Successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a2b5f30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is a csv: 'orders_data/orders.csv'\n",
      "orders\n",
      "orders\n",
      "File downloaded\n",
      "JDBC URL Created\n",
      "Table Loading is Complete.\n",
      "\n",
      "Please check PostgresDB for table:orders\n",
      "\n",
      "Tables was generated from:orders.csv\n",
      "    \n",
      "File is a csv: 'orders_data/reviews.csv'\n",
      "reviews\n",
      "reviews\n",
      "File downloaded\n",
      "JDBC URL Created\n",
      "Table Loading is Complete.\n",
      "\n",
      "Please check PostgresDB for table:reviews\n",
      "\n",
      "Tables was generated from:reviews.csv\n",
      "    \n",
      "File is a csv: 'orders_data/shipment_deliveries.csv'\n",
      "shipment_deliveries\n",
      "shipment_deliveries\n",
      "File downloaded\n",
      "JDBC URL Created\n",
      "Table Loading is Complete.\n",
      "\n",
      "Please check PostgresDB for table:shipment_deliveries\n",
      "\n",
      "Tables was generated from:shipment_deliveries.csv\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "bucket_name = \"d2b-internal-assessment-bucket\"\n",
    "\n",
    "for file in files:\n",
    "#Store file name as a variable\n",
    "    table_name = str(file['Key'])  \n",
    "    #check for .json files only\n",
    "    if table_name.endswith('.csv') == True:\n",
    "        if table_name.startswith('orders_data/orders') == True or  table_name.startswith('orders_data/reviews') == True or  table_name.startswith('orders_data/shipment_deliveries') == True:        \n",
    "            print(\"File is a csv: '{file}'\".format(file=table_name))\n",
    "            dataset = (table_name.split('/')[1]).split('.')[0]\n",
    "            tab_name = str((table_name.split('/')[1]).split('.')[0])\n",
    "            print(tab_name)\n",
    "            print(dataset)\n",
    "\n",
    "            download_string = '''s3.download_file(Bucket=bucket_name, \n",
    "            Key='{table_name}', Filename=r\"/Users/Oluwaloseyi Sekoni/csvstaging/{table_name}\")'''.format(table_name=table_name)\n",
    "        \n",
    "            exec(download_string)\n",
    "            print('File downloaded')\n",
    "            \n",
    "            read_string = '''dataset = spark.read.format(\"csv\") \\\n",
    "            .option(\"header\",\"true\").load(r\"/Users/Oluwaloseyi Sekoni/csvstaging/{table_name}\")\n",
    "            '''.format(table_name = table_name)\n",
    "        \n",
    "            exec(read_string)\n",
    "            \n",
    "            jdbc_load_function(dataset, \"overwrite\",tab_name)\n",
    "            \n",
    "            #dataset.printSchema()\n",
    "            #dataset.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6edaf711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC URL Created\n",
      "Question 1 Complete\n",
      "file exported successfully\n"
     ]
    }
   ],
   "source": [
    "Q1_query = '''(SELECT CURRENT_DATE ingestion_date ,\n",
    "SUM(CASE WHEN TO_CHAR(to_date(a.order_date, 'YYYY-MM-DD'), 'Mon') = 'Jan' THEN 1 else 0 end) tt_order_hol_jan,\n",
    "SUM(CASE WHEN TO_CHAR(to_date(a.order_date, 'YYYY-MM-DD'), 'Mon') = 'Feb' THEN 1 else 0 end) tt_order_hol_feb,\n",
    "SUM(CASE WHEN TO_CHAR(to_date(a.order_date, 'YYYY-MM-DD'), 'Mon') = 'Mar' THEN 1 else 0 end) tt_order_hol_mar,\n",
    "SUM(CASE WHEN TO_CHAR(to_date(a.order_date, 'YYYY-MM-DD'), 'Mon') = 'Apr' THEN 1 else 0 end) tt_order_hol_apr,\n",
    "SUM(CASE WHEN TO_CHAR(to_date(a.order_date, 'YYYY-MM-DD'), 'Mon') = 'May' THEN 1 else 0 end) tt_order_hol_may,\n",
    "SUM(CASE WHEN TO_CHAR(to_date(a.order_date, 'YYYY-MM-DD'), 'Mon') = 'Jun' THEN 1 else 0 end) tt_order_hol_jun,\n",
    "SUM(CASE WHEN TO_CHAR(to_date(a.order_date, 'YYYY-MM-DD'), 'Mon') = 'Jul' THEN 1 else 0 end) tt_order_hol_jul,\n",
    "SUM(CASE WHEN TO_CHAR(to_date(a.order_date, 'YYYY-MM-DD'), 'Mon') = 'Aug' THEN 1 else 0 end) tt_order_hol_aug,\n",
    "SUM(CASE WHEN TO_CHAR(to_date(a.order_date, 'YYYY-MM-DD'), 'Mon') = 'Sep' THEN 1 else 0 end) tt_order_hol_sep,\n",
    "SUM(CASE WHEN TO_CHAR(to_date(a.order_date, 'YYYY-MM-DD'), 'Mon') = 'Oct' THEN 1 else 0 end) tt_order_hol_oct,\n",
    "SUM(CASE WHEN TO_CHAR(to_date(a.order_date, 'YYYY-MM-DD'), 'Mon') = 'Nov' THEN 1 else 0 end) tt_order_hol_nov,\n",
    "SUM(CASE WHEN TO_CHAR(to_date(a.order_date, 'YYYY-MM-DD'), 'Mon') = 'Dec' THEN 1 else 0 end) tt_order_hol_dec\n",
    "FROM oluwseko3351_staging.orders a, if_common.dim_dates b\n",
    "where to_date(a.order_date, 'YYYY-MM-DD') = b.calendar_dt and day_of_the_week_num between 1 and 5 and working_day is false\n",
    "GROUP BY CURRENT_DATE) foo'''\n",
    "\n",
    "servername = \"d2b-internal-assessment-dwh.cxeuj0ektqdz.eu-central-1.rds.amazonaws.com\"\n",
    "portnumber = 5432\n",
    "dbname = \"d2b_assessment\"\n",
    "username = \"oluwseko3351\"\n",
    "password = \"QWjmGssQaY\"\n",
    "\n",
    "URL = f\"jdbc:postgresql://{servername}:{portnumber}/{dbname}\"\n",
    "print('JDBC URL Created')\n",
    "\n",
    "q1_read_query = '''q1_dataframe=spark.read\\\n",
    ".format(\"jdbc\")\\\n",
    ".option(\"url\",URL)\\\n",
    ".option(\"dbtable\",Q1_query )\\\n",
    ".option(\"user\", username)\\\n",
    ".option(\"password\", \"QWjmGssQaY\")\\\n",
    ".option(\"driver\", \"org.postgresql.Driver\")\\\n",
    ".load()'''\n",
    "\n",
    "exec(q1_read_query)\n",
    "\n",
    "load_query = '''{to_load}.write.mode(\"{write_mode}\")\\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\",URL)\\\n",
    "    .option(\"dbtable\", \"oluwseko3351_analytics.{tab_name}\")\\\n",
    "    .option(\"user\", username)\\\n",
    "    .option(\"password\", \"QWjmGssQaY\")\\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\\\n",
    "    .save()'''.format(to_load = \"q1_dataframe\",write_mode=\"overwrite\", tab_name = \"agg_public_holiday\")\n",
    "\n",
    "exec(load_query)\n",
    "\n",
    "print('Question 1 Complete')\n",
    "\n",
    "# Saving file\n",
    "q1_dataframe_df = q1_dataframe.toPandas()\n",
    "q1_dataframe_df.to_csv(r\"C:\\Users\\Oluwaloseyi Sekoni\\exportstaging\\agg_public_holiday.csv\", index=False)\n",
    "\n",
    "print('file exported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86b4c281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC URL Created\n",
      "Question 2 Complete\n",
      "file exported successfully\n"
     ]
    }
   ],
   "source": [
    "Q2_query = '''(select CURRENT_DATE ingestion_date, \n",
    "(select COUNT(*)FROM oluwseko3351_staging.orders a, oluwseko3351_staging.shipment_deliveries b\n",
    "where a.order_id = b.order_id and to_date(b.shipment_date, 'YYYY-MM-DD') >= to_date(a.order_date, 'YYYY-MM-DD') +6\n",
    "and delivery_date is NULL) tt_late_shipments,\n",
    "(select COUNT(*) FROM oluwseko3351_staging.orders a, oluwseko3351_staging.shipment_deliveries b\n",
    "where a.order_id = b.order_id and CURRENT_DATE >= to_date(a.order_date, 'YYYY-MM-DD') +15\n",
    "and delivery_date is NULL and b.shipment_date is NULL) tt_undelivered_items) query'''\n",
    "\n",
    "servername = \"d2b-internal-assessment-dwh.cxeuj0ektqdz.eu-central-1.rds.amazonaws.com\"\n",
    "portnumber = 5432\n",
    "dbname = \"d2b_assessment\"\n",
    "username = \"oluwseko3351\"\n",
    "password = \"QWjmGssQaY\"\n",
    "\n",
    "URL = f\"jdbc:postgresql://{servername}:{portnumber}/{dbname}\"\n",
    "print('JDBC URL Created')\n",
    "\n",
    "q1_read_query = '''q2_dataframe=spark.read\\\n",
    ".format(\"jdbc\")\\\n",
    ".option(\"url\",URL)\\\n",
    ".option(\"dbtable\",Q2_query )\\\n",
    ".option(\"user\", username)\\\n",
    ".option(\"password\", \"QWjmGssQaY\")\\\n",
    ".option(\"driver\", \"org.postgresql.Driver\")\\\n",
    ".load()'''\n",
    "\n",
    "exec(q1_read_query)\n",
    "\n",
    "load_query = '''{to_load}.write.mode(\"{write_mode}\")\\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\",URL)\\\n",
    "    .option(\"dbtable\", \"oluwseko3351_analytics.{tab_name}\")\\\n",
    "    .option(\"user\", username)\\\n",
    "    .option(\"password\", \"QWjmGssQaY\")\\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\\\n",
    "    .save()'''.format(to_load = \"q2_dataframe\",write_mode=\"overwrite\", tab_name = \"agg_shipments\")\n",
    "\n",
    "exec(load_query)\n",
    "\n",
    "print('Question 2 Complete')\n",
    "\n",
    "# Saving file\n",
    "q2_dataframe_df = q2_dataframe.toPandas()\n",
    "q2_dataframe_df.to_csv(r\"C:\\Users\\Oluwaloseyi Sekoni\\exportstaging\\agg_shipments.csv\", index=False)\n",
    "\n",
    "print('file exported successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f75830cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC URL Created\n",
      "Question 3 Complete\n",
      "file exported successfully\n"
     ]
    }
   ],
   "source": [
    "Q3_query = '''(select CURRENT_DATE ingestion_date,\n",
    "(select product_name from if_common.dim_products a where product_id =\n",
    "(select product_id from (select product_id, count(*) FROM oluwseko3351_staging.reviews group by product_id order by 2 desc\n",
    "LIMIT 1) foo)::INTEGER) product_name,\n",
    "(select order_date from \n",
    "(select to_date(a.order_date, 'YYYY-MM-DD') order_date, count(*) count FROM oluwseko3351_staging.orders a where product_id =\n",
    "(select product_id from (select product_id, count(*) FROM oluwseko3351_staging.reviews group by product_id order by 2 desc\n",
    "LIMIT 1) foo) group by to_date(a.order_date, 'YYYY-MM-DD') order by 2 desc LIMIT 1)foo) most_ordered_day,\n",
    "(select CASE WHEN day_of_the_week_num between 1 and 5 and working_day is false THEN true else false end as is_public_holiday \n",
    "from if_common.dim_dates where calendar_dt = (select order_date from \n",
    "(select to_date(a.order_date, 'YYYY-MM-DD') order_date, count(*) count FROM oluwseko3351_staging.orders a where product_id =\n",
    "(select product_id from (select product_id, count(*) FROM oluwseko3351_staging.reviews group by product_id order by 2 desc\n",
    "LIMIT 1) foo) group by to_date(a.order_date, 'YYYY-MM-DD') order by 2 desc LIMIT 1)foo)) is_public_holiday,\n",
    "(select sum from (select product_id, count(*) COUNT, SUM(review::INTEGER) SUM FROM oluwseko3351_staging.reviews group by product_id order by 2 desc\n",
    "LIMIT 1) foo) tt_review_points,\n",
    "(select pct_one_star_review from( \n",
    "select product_id, count(*) count, \n",
    "(sum(case when review = '1' then 1 else 0 end)::decimal /count(*)::decimal )*100 pct_one_star_review\n",
    "FROM oluwseko3351_staging.reviews group by product_id order by 2 desc\n",
    "LIMIT 1) foo) pct_one_star_review,\n",
    "(select pct_two_star_review from( \n",
    "select product_id, count(*) count, \n",
    "(sum(case when review = '2' then 1 else 0 end)::decimal /count(*)::decimal )*100 pct_two_star_review\n",
    "FROM oluwseko3351_staging.reviews group by product_id order by 2 desc\n",
    "LIMIT 1) foo) pct_two_star_review,\n",
    "(select pct_three_star_review from( \n",
    "select product_id, count(*) count, \n",
    "(sum(case when review = '3' then 1 else 0 end)::decimal /count(*)::decimal )*100 pct_three_star_review\n",
    "FROM oluwseko3351_staging.reviews group by product_id order by 2 desc\n",
    "LIMIT 1) foo) pct_three_star_review,\n",
    "(select pct_four_star_review from( \n",
    "select product_id, count(*) count, \n",
    "(sum(case when review = '4' then 1 else 0 end)::decimal /count(*)::decimal )*100 pct_four_star_review\n",
    "FROM oluwseko3351_staging.reviews group by product_id order by 2 desc\n",
    "LIMIT 1) foo) pct_four_star_review,\n",
    "(select pct_five_star_review from( \n",
    "select product_id, count(*) count, \n",
    "(sum(case when review = '3' then 1 else 0 end)::decimal /count(*)::decimal )*100 pct_five_star_review\n",
    "FROM oluwseko3351_staging.reviews group by product_id order by 2 desc\n",
    "LIMIT 1) foo) pct_five_star_review,\n",
    "(SELECT ((select COUNT(*)FROM oluwseko3351_staging.orders a, oluwseko3351_staging.shipment_deliveries b\n",
    "where product_id =(select product_id from (select product_id, count(*) FROM oluwseko3351_staging.reviews group by product_id order by 2 desc\n",
    "LIMIT 1) foo)  and a.order_id = b.order_id and to_date(b.shipment_date, 'YYYY-MM-DD') < to_date(a.order_date, 'YYYY-MM-DD') +6\n",
    "and delivery_date is NOT NULL)::decimal/(select COUNT(*)FROM oluwseko3351_staging.orders where product_id = (select product_id from (select product_id, count(*) FROM oluwseko3351_staging.reviews group by product_id order by 2 desc\n",
    "LIMIT 1) foo))::decimal) * 100) pct_early_shipments,\n",
    "(SELECT ((select COUNT(*)FROM oluwseko3351_staging.orders a, oluwseko3351_staging.shipment_deliveries b\n",
    "where product_id =(select product_id from (select product_id, count(*) FROM oluwseko3351_staging.reviews group by product_id order by 2 desc\n",
    "LIMIT 1) foo)  and a.order_id = b.order_id and to_date(b.shipment_date, 'YYYY-MM-DD') >= to_date(a.order_date, 'YYYY-MM-DD') +6\n",
    "and delivery_date is NULL)::decimal/(select COUNT(*)FROM oluwseko3351_staging.orders where product_id = (select product_id from (select product_id, count(*) FROM oluwseko3351_staging.reviews group by product_id order by 2 desc\n",
    "LIMIT 1) foo))::decimal) * 100) pct_late_shipments) query'''\n",
    "\n",
    "servername = \"d2b-internal-assessment-dwh.cxeuj0ektqdz.eu-central-1.rds.amazonaws.com\"\n",
    "portnumber = 5432\n",
    "dbname = \"d2b_assessment\"\n",
    "username = \"oluwseko3351\"\n",
    "password = \"QWjmGssQaY\"\n",
    "\n",
    "URL = f\"jdbc:postgresql://{servername}:{portnumber}/{dbname}\"\n",
    "print('JDBC URL Created')\n",
    "\n",
    "q1_read_query = '''q3_dataframe=spark.read\\\n",
    ".format(\"jdbc\")\\\n",
    ".option(\"url\",URL)\\\n",
    ".option(\"dbtable\",Q3_query )\\\n",
    ".option(\"user\", username)\\\n",
    ".option(\"password\", \"QWjmGssQaY\")\\\n",
    ".option(\"driver\", \"org.postgresql.Driver\")\\\n",
    ".load()'''\n",
    "\n",
    "exec(q1_read_query)\n",
    "\n",
    "load_query = '''{to_load}.write.mode(\"{write_mode}\")\\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\",URL)\\\n",
    "    .option(\"dbtable\", \"oluwseko3351_analytics.{tab_name}\")\\\n",
    "    .option(\"user\", username)\\\n",
    "    .option(\"password\", \"QWjmGssQaY\")\\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\\\n",
    "    .save()'''.format(to_load = \"q3_dataframe\",write_mode=\"overwrite\", tab_name = \"best_performing_product\")\n",
    "\n",
    "exec(load_query)\n",
    "\n",
    "print('Question 3 Complete')\n",
    "\n",
    "# Saving file\n",
    "q3_dataframe_df = q3_dataframe.toPandas()\n",
    "q3_dataframe_df.to_csv(r\"C:\\Users\\Oluwaloseyi Sekoni\\exportstaging\\best_performing_product.csv\", index=False)\n",
    "bucket_name = \"d2b-internal-assessment-bucket\"\n",
    "print('file exported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ad4fa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 uploads complete\n"
     ]
    }
   ],
   "source": [
    "bucket_name = \"d2b-internal-assessment-bucket\"\n",
    "\n",
    "s3 = boto3.resource('s3') \n",
    "\n",
    "s3.Bucket(bucket_name).upload_file(r\"C:\\Users\\Oluwaloseyi Sekoni\\exportstaging\\agg_public_holiday.csv\",'analytics_export/oluwseko3351/agg_public_holiday.csv')\n",
    "\n",
    "\n",
    "s3.Bucket(bucket_name).upload_file(r\"C:\\Users\\Oluwaloseyi Sekoni\\exportstaging\\agg_shipments.csv\",'analytics_export/oluwseko3351/agg_shipments.csv')\n",
    "\n",
    "\n",
    "s3.Bucket(bucket_name).upload_file(r\"C:\\Users\\Oluwaloseyi Sekoni\\exportstaging\\best_performing_product.csv\",'analytics_export/oluwseko3351/best_performing_product.csv')\n",
    "\n",
    "print('s3 uploads complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f06c89ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/analytics_export/destaman4118/agg_public_holiday.csv\n",
      "/analytics_export/destaman4118/agg_shipments.csv\n",
      "/analytics_export/destaman4118/best_performing_product.csv\n",
      "/analytics_export/judendu4707/agg_public.csv\n",
      "/analytics_export/judendu4707/agg_shipments.csv\n",
      "/analytics_export/judendu4707/best_product.csv\n",
      "/analytics_export/nasibell8682/agg_public_holiday.csv\n",
      "/analytics_export/nasibell8682/agg_shipments.csv\n",
      "53e35838-ad59-4417-97e3-5f243b051c10.csv\n",
      "950532c9-a561-4513-810b-137d51ec6bea.csv\n",
      "9f63b10a-7102-4894-8e8c-3a5e8a75578d.csv\n",
      "GeoSegmentatie.csv\n",
      "abayojam7722/agg_public_holiday.csv\n",
      "abayojam7722/agg_shipments.csv\n",
      "abayojam7722/best_performing_product.csv\n",
      "adewale_analytics/agg_public_holiday.csv_0_0_0.csv.gz\n",
      "adewale_analytics/data_0_0_0.csv.gz\n",
      "agg_public_holiday.csv\n",
      "agg_shipments.csv\n",
      "analytics_export/\n",
      "analytics_export/adefakin6735/agg_public_holiday.csv\n",
      "analytics_export/adefakin6735/agg_shipments.csv\n",
      "analytics_export/adefakin6735/best_performing_products.csv\n",
      "analytics_export/agg_public_holiday.csv\n",
      "analytics_export/agg_shipments.csv\n",
      "analytics_export/best_performing_product.csv\n",
      "analytics_export/byroneji4734/agg_public_holiday.csv\n",
      "analytics_export/byroneji4734/agg_shipments.csv\n",
      "analytics_export/byroneji4734/best_performing_product.csv\n",
      "analytics_export/charekpe8461/agg_public_holiday.csv\n",
      "analytics_export/charekpe8461/agg_shipments.csv\n",
      "analytics_export/charekpe8461/best_performing_product.csv\n",
      "analytics_export/chinchin6308/agg_public_holiday.csv\n",
      "analytics_export/chinchin6308/agg_shipments.csv\n",
      "analytics_export/chinchin6308/best_performing_product.csv\n",
      "analytics_export/chisorik5367/agg_public_holiday.csv\n",
      "analytics_export/chisorik5367/agg_shipments.csv\n",
      "analytics_export/chisorik5367/best_performing_product.csv\n",
      "analytics_export/chukogbe1619/agg_public_holiday.csv\n",
      "analytics_export/chukogbe1619/agg_shipments.csv\n",
      "analytics_export/chukogbe1619/best_performing_product.csv\n",
      "analytics_export/dewaleofficial/agg_public_holiday.csv\n",
      "analytics_export/dewaleofficial/agg_shipments.csv\n",
      "analytics_export/dewaleofficial/best_performing_product.csv\n",
      "analytics_export/emmafung6037/agg_public_holiday.csv\n",
      "analytics_export/emmafung6037/agg_shipments.csv\n",
      "analytics_export/emmafung6037/best_performing_product.csv\n",
      "analytics_export/emmaoffi5076/agg_public_holiday.csv\n",
      "analytics_export/emmaoffi5076/agg_shipments.csv\n",
      "analytics_export/emmaoffi5076/best_performing_product.csv\n",
      "analytics_export/ezekjoaq8089/agg_public_holiday.csv\n",
      "analytics_export/ezekjoaq8089/agg_shipments.csv\n",
      "analytics_export/ezekjoaq8089/best_performing_product.csv\n",
      "analytics_export/idrialug9071/agg_public_holiday.csv\n",
      "analytics_export/idrialug9071/agg_shipments.csv\n",
      "analytics_export/idrialug9071/best_performing_product.csv\n",
      "analytics_export/isaaomol5182/agg_public_holiday.csv\n",
      "analytics_export/isaaomol5182/agg_shipments.csv\n",
      "analytics_export/isaaomol5182/best_performing_product.csv\n",
      "analytics_export/jamitija5771/agg_public_holiday.csv\n",
      "analytics_export/jamitija5771/agg_shipments.csv\n",
      "analytics_export/jamitija5771/best_performing_product.csv\n",
      "analytics_export/jennebe7150/agg_public_holiday.csv\n",
      "analytics_export/jennebe7150/agg_shipments.csv\n",
      "analytics_export/jennebe7150/best_perfoming_product.csv\n",
      "analytics_export/joseogwu4489/agg_public_holiday.csv\n",
      "analytics_export/joseogwu4489/agg_shipments.csv\n",
      "analytics_export/joseogwu4489/best_performing_product.csv\n",
      "analytics_export/kayobalo2990/agg_public_holiday.csv\n",
      "analytics_export/kayobalo2990/agg_shipments.csv\n",
      "analytics_export/kayobalo2990/best_performing_product.csv\n",
      "analytics_export/kenndago1965/agg_public_holiday\n",
      "analytics_export/kenndago1965/agg_public_holiday.csv\n",
      "analytics_export/kenndago1965/agg_shipments.csv\n",
      "analytics_export/kenndago1965/best_performing_product\n",
      "analytics_export/kenndago1965/best_performing_product.csv\n",
      "analytics_export/kenndago1965/{file}\n",
      "analytics_export/moseikea2893/agg_public_holiday.csv\n",
      "analytics_export/moseikea2893/agg_shipment.csv\n",
      "analytics_export/moseikea2893/best_performing_product.csv\n",
      "analytics_export/moseikea2893/orders.csv\n",
      "analytics_export/moseikea2893/reviews.csv\n",
      "analytics_export/moseikea2893/shipment_deliveries.csv\n",
      "analytics_export/muhajimo9824/agg_public_holiday.csv\n",
      "analytics_export/muhajimo9824/agg_shipments.csv\n",
      "analytics_export/okondivi4898\n",
      "analytics_export/okondivi4898/\n",
      "analytics_export/okondivi4898\\agg_public_holidayt.csv\n",
      "analytics_export/okondivi4898\\agg_shipments.csv\n",
      "analytics_export/okondivi4898\\best_performing_product.csv\n",
      "analytics_export/olueokol5948/agg_public_holiday.csv\n",
      "analytics_export/olueokol5948/agg_shipments.csv\n",
      "analytics_export/olueokol5948/best_performing_product.csv\n",
      "analytics_export/oluwolad6179/agg_public_holiday.csv\n",
      "analytics_export/oluwolad6179/agg_shipments.csv\n",
      "analytics_export/oluwolad6179/best_performing_product.csv\n",
      "analytics_export/oluwseko3351/agg_public_holiday.csv\n",
      "analytics_export/oluwseko3351/agg_shipments.csv\n",
      "analytics_export/oluwseko3351/best_performing_product.csv\n",
      "analytics_export/onidwale1371/agg_public_holiday.csv\n",
      "analytics_export/onidwale1371/agg_shipments.csv\n",
      "analytics_export/onidwale1371/best_performing_product.csv\n",
      "analytics_export/paulnwos2601/AGG_PUBLIC_HOLIDAY2.csv\n",
      "analytics_export/paulnwos2601/AGG_SHIPMENTS.csv\n",
      "analytics_export/paulnwos2601/BEST_PERFORMING_PRODUCT.csv\n",
      "analytics_export/peluader5437/agg_public_holiday.csv\n",
      "analytics_export/peluader5437/agg_shipments.csv\n",
      "analytics_export/peluader5437/best_performing_product.csv\n",
      "analytics_export/somtmoma5254/\n",
      "analytics_export/somtmoma5254/agg_public_holiday.csv\n",
      "analytics_export/somtmoma5254/agg_shipments.csv\n",
      "analytics_export/somtmoma5254/best_performing_product.csv\n",
      "analytics_export/sunkotit4665/agg_public_holiday.csv\n",
      "analytics_export/sunkotit4665/agg_shipments.csv\n",
      "analytics_export/sunkotit4665/best_performing_product.csv\n",
      "analytics_export/user1224/agg_public_holiday.csv\n",
      "analytics_export/user1234/agg_public_holiday.csv\n",
      "analytics_export/user1234/best_performing_product.csv\n",
      "analytics_export/victoko3736/best_performing_product.csv\n",
      "analytics_export/waliaden9255/agg_public_holiday.csv\n",
      "analytics_export/waliaden9255/agg_shipments.csv\n",
      "analytics_export/waliaden9255/best_performing_product.csv\n",
      "analytics_export/yazejibi6672/agg_public_holiday.csv\n",
      "analytics_export/yazejibi6672/agg_shipments.csv\n",
      "analytics_export/yazejibi6672/best_performing_product.csv\n",
      "analytics_export\\okondivi4898\n",
      "analytics_export\\okondivi4898\\agg_public_holidayt.csv\n",
      "analytics_export\\okondivi4898\\agg_shipments.csv\n",
      "analytics_export\\okondivi4898\\best_performing_product.csv\n",
      "best_performing_product.csv\n",
      "data_0_0_0.csv.gz\n",
      "e223bba6-fdb2-48f0-b550-1cc25a9294b8.csv\n",
      "kolaobaj9476/agg_public_holiday.csv\n",
      "kolaobaj9476/agg_shipments.csv\n",
      "kolaobaj9476/best_performing_product.csv\n",
      "objectkey\n",
      "orders_data/\n",
      "orders_data/analytics_export/murtodun9658/agg_public_holiday.csv\n",
      "orders_data/analytics_export/murtodun9658/agg_shipments.csv\n",
      "orders_data/analytics_export/murtodun9658/best_performing_product.csv\n",
      "orders_data/analytics_export/murtodun9658/late_shipments.csv\n",
      "orders_data/analytics_export/murtodun9658/undelivered_shipments.csv\n",
      "orders_data/orders.csv\n",
      "orders_data/reviews.csv\n",
      "orders_data/shipment_deliveries.csv\n",
      "s3://d2b-internal-assessment-bucket/analytics_export/babaomot1600/agg_public_holiday.csv\n",
      "s3://d2b-internal-assessment-bucket/analytics_export/babaomot1600/agg_shipments.csv\n",
      "s3://d2b-internal-assessment-bucket/analytics_export/babaomot1600/best_performing_product.csv\n",
      "s3://d2b-internal-assessment-bucket/analytics_export/judendu4707/agg_public_holiday.csv\n",
      "s3://d2b-internal-assessment-bucket/analytics_export/judendu4707/agg_shipment.csv\n",
      "s3://d2b-internal-assessment-bucket/analytics_export/judendu4707/best_product.csv\n",
      "shipments_deliveries.csv\n",
      "test/\n",
      "test/agg_public_holiday\n",
      "test/agg_public_holiday.csv\n",
      "test/agg_public_holiday_0_0_0.csv\n"
     ]
    }
   ],
   "source": [
    "# confirm file upload completed successfully\n",
    "\n",
    "bucket_name = \"d2b-internal-assessment-bucket\"\n",
    "\n",
    "for file in files:\n",
    "    print(file['Key'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
